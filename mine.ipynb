{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mine.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNjzJ4DirzeGZTfVR6YmH32",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/doaa1adel/Ear-Recognition-Challenge/blob/master/mine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WcoDkHkVjIX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "a7bf74c3-9ddf-46d0-8740-56f3619b539d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "root_path = 'gdrive/My Drive/Colab Notebooks/'  #change dir to your project folder"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gahMU1DYgdN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os,shutil\n",
        "import cv2,keras\n",
        "import numpy as np\n",
        "from imgaug import augmenters as iaa\n",
        "import skimage.io as skio\n",
        "from keras.applications.xception import Xception\n",
        "from keras.models import Model\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3iBn8_4YlB-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = '/content/gdrive/My Drive/Colab Notebooks/'\n",
        "tr_FN = 'Train Dataset'\n",
        "trainset = \"training_set\"\n",
        "testset = \"testing_set\"\n",
        "validation_percentage = 20;\n",
        "total_subs = 150\n",
        "epochs = 2"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqCj0HerYpqf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_au(x,f):\n",
        "    flip = iaa.Sequential([iaa.Fliplr(0.5)]).augment_images(x)\n",
        "    skio.imsave(f + 'flip.png',flip)\n",
        "    crop = iaa.Sequential([iaa.Crop(percent=(0, 0.1))]).augment_images(x)\n",
        "    skio.imsave(f + 'crop.png',crop)\n",
        "    GB = iaa.Sequential([iaa.GaussianBlur(sigma=(0, 3.0))]).augment_images(x)\n",
        "    skio.imsave(f + 'GB.png',GB)\n",
        "    GN = iaa.Sequential([iaa.AdditiveGaussianNoise(scale=(0.0, 0.2))]).augment_images(x)\n",
        "    skio.imsave(f + 'GN.png',GN)\n",
        "    CN = iaa.Sequential([iaa.ContrastNormalization(0.5, per_channel=0.5)]).augment_images(x)\n",
        "    skio.imsave(f + 'CN.png',CN)\n",
        "    BR = iaa.Sequential([iaa.Multiply((0.8,1.2))]).augment_images(x)\n",
        "    skio.imsave(f + 'BR.png',BR)\n",
        "    Scale = iaa.Sequential([iaa.Affine(\n",
        "            scale={\"x\": (0.8, 1.2), \"y\": (0.8,1.2)})]).augment_images(x)\n",
        "    skio.imsave(f + 'Scale.png',Scale)\n",
        "    rotate = iaa.Sequential([iaa.Affine(rotate=(-45, 45))]).augment_images(x)\n",
        "    skio.imsave(f + 'rotate.png',rotate)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eRCBb65YunI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def createFolder(folderName):\n",
        "    \"\"\"\n",
        "    Safely create folder when needed\n",
        "    :param folderName : the directory that you  want to safely create\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "    if not os.path.exists(folderName):\n",
        "        try:\n",
        "            os.makedirs(folderName)\n",
        "        except OSError as exc:  # Guard against race condition\n",
        "            if exc.errno != exc.errno.EEXIST:\n",
        "                raise\n",
        "\n",
        "def split_trianing_testing(images,image_path,subject):\n",
        "    #take only .png files and store it in a list\n",
        "    ears = []\n",
        "    for image in images:\n",
        "        if (image.endswith(\".png\")):\n",
        "            ears.append(image)\n",
        "        else:\n",
        "        \tfile = os.path.join(PATH,trainset,subject,image)\n",
        "       \t\tshutil.move(os.path.join(image_path,image),file)\n",
        "    no_trian_data = int(0.6 * len(ears))\n",
        "    for i,_ in enumerate(ears):\n",
        "       \tif (i <= no_trian_data-1):\n",
        "       \t\tfile = os.path.join(PATH,trainset,subject,ears[i])\n",
        "       \t\tshutil.move(os.path.join(image_path,ears[i]),file)\n",
        "       \telse:\n",
        "       \t\tfile = os.path.join(PATH,testset,subject,ears[i])\n",
        "       \t\tshutil.move(os.path.join(image_path,ears[i]),file)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4S7lieIZH7X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "cellView": "code",
        "outputId": "b1a2d569-55cb-4ce3-e004-69177a388633"
      },
      "source": [
        "#@title Default title text\n",
        "#take 150 subjects from given trianing dataset and split 60-40 from every subject and\n",
        "#for training and testing purpose\n",
        "def creating_dataset_without_aug():\n",
        "\tmode = tr_FN\n",
        "\tmode_path = os.path.join(PATH,mode)\n",
        "\tsubjects = os.listdir(mode_path)\n",
        "\tfor subject in subjects:\n",
        "\t\tif (int(subject) <= 150):\n",
        "\t\t\tcreateFolder(os.path.join(PATH,trainset,subject))\n",
        "\t\t\tcreateFolder(os.path.join(PATH,testset,subject))\n",
        "\t\t\timage_path  = os.path.join(mode_path,subject)\n",
        "\t\t\timages = os.listdir(image_path)\n",
        "\t\t\t#splitting the trainig and testing in dataset as 60 and 40 percent\n",
        "\t\t\tsplit_trianing_testing(images,image_path,subject)\n",
        "\t\t\tif (len(os.listdir(image_path)) == 0):\n",
        "\t\t\t\tos.rmdir(image_path)\n",
        "\tif (len(os.listdir(mode_path)) == 0):\n",
        "\t\tos.rmdir(mode_path)\n",
        "  \n",
        "#function for splitting training and validation from trainset\n",
        "def split_data(data,label,valid_len):\n",
        "    valid_len = int(valid_len*len(data)/100)\n",
        "    return (data[0:len(data)-valid_len],label[0:len(data)-valid_len],\n",
        "            data[len(data)-valid_len:len(data)],label[len(data)-valid_len:len(data)])\n",
        "    \n",
        "#function for data augmnetation\n",
        "def data_after_augmentation():\n",
        "\tprint('data_augmentation starts')\n",
        "\tmode_path = os.path.join(PATH,trainset)\n",
        "\tsubjects = os.listdir(mode_path)\n",
        "\tfor subject in subjects:\n",
        "\t\timage_path = os.path.join(mode_path,subject)\n",
        "\t\timages = os.listdir(image_path)\n",
        "\t\tfor image in images:\n",
        "\t\t\tif image.endswith(\".png\"):\n",
        "\t\t\t\tfile = os.path.join(image_path,image)\n",
        "\t\t\t\timg = cv2.resize(cv2.imread(file),(100,100))\n",
        "\t\t\t\tdata_au(img,os.path.splitext(file)[0])\n",
        "\n",
        "#function for collecting final datasset\n",
        "def data(mode):\n",
        "\tprint('train data')\n",
        "\ttotal_images = []\n",
        "\tlabel = []\n",
        "\tx_tr = []\n",
        "\ty_tr = []\n",
        "\tx_va = []\n",
        "\ty_va = []\n",
        "\tmode_path = os.path.join(PATH,mode)\n",
        "\tsubjects = os.listdir(mode_path)\n",
        "\tfor subject in subjects:\n",
        "\t\timage_path = os.path.join(mode_path,subject)\n",
        "\t\timages = os.listdir(image_path)\n",
        "\t\tfor image in images:\n",
        "\t\t\tif image.endswith(\".png\"):\n",
        "\t\t\t\tfile = os.path.join(image_path,image)\n",
        "\t\t\t\ttotal_images.append(cv2.resize(cv2.imread(file),(100,100)))\n",
        "\t\t\t\tlabel.append(int(subject))\n",
        "\n",
        "if (mode == trainset):\n",
        "\t\ttotal_images = np.array(total_images)\n",
        "\t\tlabel = np.array(label)\n",
        "\n",
        "\t\t[x_t,y_t,x_v,y_v] = split_data(total_images,label,validation_percentage)\n",
        "\n",
        "\t\tno_training_images = x_t.shape[0]\n",
        "\t\tno_validation_images = x_v.shape[0]\n",
        "\t\tx_tr.append(x_t)\n",
        "\t\ty_tr.append(y_t)\n",
        "\t\tx_va.append(x_v)\n",
        "\t\ty_va.append(y_v)\n",
        "\t\ttotal_images = []\n",
        "\t\tlabel = []\n",
        "\t  no_subjects = len(subjects)\n",
        "\t\tx_tr = np.reshape(np.array(x_tr),(no_subjects*no_training_images,100,100,3))\n",
        "\t\ty_tr = np.reshape(np.array(y_tr),(no_subjects*no_training_images,1))\n",
        "\t\tx_va = np.reshape(np.array(x_va),(no_subjects*no_validation_images,100,100,3))\n",
        "\t\ty_va = np.reshape(np.array(y_va),(no_subjects*no_validation_images,1))\n",
        "\t\treturn x_tr,y_tr,x_va,y_va\n",
        "else:\n",
        "\t\ttotal_images = np.array(total_images)\n",
        "\t\tlabel = np.reshape(np.array(label),(len(label),1))\n",
        "\t\treturn total_images,label\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-73-a61a814aea52>\"\u001b[0;36m, line \u001b[0;32m75\u001b[0m\n\u001b[0;31m    no_subjects = len(subjects)\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUOEHHPpZXkh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "outputId": "e8fbe50f-5c90-4c36-c2bb-4bf873522088"
      },
      "source": [
        "creating_dataset_without_aug()\n",
        "print(\"--------------------------------------------------------\")\n",
        "print('dataset splitted as 60-40 from training set')\n",
        "\n",
        "data_after_augmentation()\n",
        "print(\"--------------------------------------------------------\")\n",
        "print('data augmentation done for splitted train set (60 %)')\n",
        "\n",
        "[x_train,y_train,x_valid,y_valid] = data(trainset)\n",
        "\n",
        "\n",
        "\n",
        "#[x_train,y_train,x_valid,y_valid] = split_data(trainset,label,validation_percentage)\n",
        "print('final trianing dataset collected')\n",
        "print(\"x_train: \",x_train.shape)\n",
        "print(\"y_train: \",y_train.shape)\n",
        "print(\"x_valid: \",x_valid.shape)\n",
        "print(\"y_valid\",y_valid.shape)\n",
        "print (\"-------------------------------------------------------\")\n",
        "\n",
        "\n",
        "[x_test,y_test] = data(testset)\n",
        "print(\"--------------------------------------------------------\")\n",
        "print('final test data collected')\n",
        "print (x_test.shape)\n",
        "print(y_test.shape)\n"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------\n",
            "dataset splitted as 60-40 from training set\n",
            "data_augmentation starts\n",
            "--------------------------------------------------------\n",
            "data augmentation done for splitted train set (60 %)\n",
            "train data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-be976d43ce16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data augmentation done for splitted train set (60 %)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-66-4b8df4b36ec3>\u001b[0m in \u001b[0;36mdata\u001b[0;34m(mode)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtrainset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0mno_subjects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubjects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 \u001b[0mx_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_subjects\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mno_training_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m                 \u001b[0my_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_subjects\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mno_training_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0mx_va\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_va\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_subjects\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mno_validation_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'no_training_images' referenced before assignment"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYsmR8DHZcLy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, total_subs+1,dtype='int32')\n",
        "y_valid = keras.utils.to_categorical(y_valid, total_subs+1,dtype='int32')\n",
        "\n",
        "y_train = y_train[:,0:total_subs]\n",
        "y_valid = y_valid[:,0:total_subs]\n",
        "\n",
        "print(y_train[0])\n",
        "print(y_valid[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nRWzycPZocp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create model and fit the model\n",
        "base_model = Xception(include_top=False, weights='imagenet',input_shape=x_train[0].shape)\n",
        "\n",
        "x = base_model.output\n",
        "x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "predictions = keras.layers.Dense(total_subs,activation='softmax')(x)\n",
        "\n",
        "model = Model(base_model.input,predictions)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zum9yj2CXnJe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#for freezing the Xception layers\n",
        "for layer in base_model.layers:\n",
        "\tlayer.trainable = False\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=70,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_valid, y_valid))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3AFNg_GZtDh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = np.argmax(model.predict(x_test),axis = 1)\n",
        "results = np.reshape(results,(len(results),1))\n",
        "\n",
        "#accuracy\n",
        "\n",
        "print(\"Accuracy: \",(sum(results == y_test))/len(results) * 100)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}